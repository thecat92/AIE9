{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ub1OLYZQvz"
   },
   "source": [
    "# Session 10: Using Ragas to Evaluate an Agent Application built with LangChain and LangGraph\n",
    "\n",
    "In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n",
    "\n",
    "While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n",
    "\n",
    "We'll:\n",
    "\n",
    "- Collect our data\n",
    "- Create a simple Agent application\n",
    "- Evaluate our Agent application\n",
    "\n",
    "> NOTE: This notebook is very lightly modified from Ragas' [LangGraph tutorial](https://docs.ragas.io/en/stable/howtos/integrations/_langgraph_agent_evaluation/)!\n",
    "\n",
    "## ü§ù Breakout Room #2\n",
    "  - Task 1: Installing Required Libraries\n",
    "  - Task 2: Set Environment Variables\n",
    "  - Task 3: Building a ReAct Agent with Metal Price Tool\n",
    "  - Task 4: Implementing the Agent Graph Structure\n",
    "  - Task 5: Converting Agent Messages to Ragas Evaluation Format\n",
    "  - Task 6: Evaluating the Agent's Performance using Ragas Metrics\n",
    "  - ***Activity #1: Evaluate Tool Call Accuracy***\n",
    "  - ***Activity #2: Evaluate Topic Adherence***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Ms4ngAZQv1"
   },
   "source": [
    "## Task 1: Installing Required Libraries\n",
    "\n",
    "If you have not already done so, install the required libraries using the uv package manager:\n",
    "``` bash\n",
    "\n",
    "uv sync\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Set Environment Variables:\n",
    "\n",
    "We'll also need to provide our API keys.\n",
    "> NOTE: In addition to OpenAI's models, this notebook will be creating a metals pricing tool using the API from metals.dev. Please be sure to sign up for an account on [metals.dev](https://metals.dev/) to get your API key.\n",
    "You have two options for supplying your API keys in this session:\n",
    "- Use environment variables (see Prerequisite #2 in the README.md)\n",
    "- Provide them via a prompt when the notebook runs\n",
    "\n",
    "The following code will load all of the environment variables in your `.env`. Then, it checks for the two API keys we need. If they are not there, it will prompt you to provide them.\n",
    "\n",
    "First, OpenAI's for our LLM/embedding model combination!\n",
    "\n",
    "Second, metals.dev's for our metals pricing tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lB5bVnoV7rz-",
    "outputId": "e06d119b-fc01-466f-864c-f63bc1c299b2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")\n",
    "\n",
    "if not os.environ.get(\"METAL_API_KEY\"):\n",
    "    os.environ[\"METAL_API_KEY\"] = getpass(\"Please enter your metals.dev API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJJ-WKWMZQv2"
   },
   "source": [
    "## Task 3: Building a ReAct Agent with Metal Price Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SduQYJbZQv3"
   },
   "source": [
    "### Define the get_metal_price Tool\n",
    "\n",
    "The get_metal_price tool will be used by the agent to fetch the price of a specified metal. We'll create this tool using the @tool decorator from LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1X2TsFLfZQv3"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the tools for the agent to use\n",
    "@tool\n",
    "def get_metal_price(metal_name: str) -> float:\n",
    "    \"\"\"Fetches the current per gram price of the specified metal.\n",
    "\n",
    "    Args:\n",
    "        metal_name : The name of the metal (e.g., 'gold', 'silver', 'platinum').\n",
    "\n",
    "    Returns:\n",
    "        float: The current price of the metal in dollars per gram.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the specified metal is not found in the data source.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metal_name = metal_name.lower().strip()\n",
    "        url = f\"https://api.metals.dev/v1/latest?api_key={os.environ['METAL_API_KEY']}&currency=USD&unit=toz\"\n",
    "        headers = CaseInsensitiveDict()\n",
    "        headers[\"Accept\"] = \"application/json\"\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        print(resp)\n",
    "        metal_price = resp.json()[\"metals\"]\n",
    "        if metal_name not in metal_price:\n",
    "            raise KeyError(\n",
    "                f\"Metal '{metal_name}' not found. Available metals: {', '.join(metal_price['metals'].keys())}\"\n",
    "            )\n",
    "        return metal_price[metal_name]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching metal price: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j85XikcLZQv4"
   },
   "source": [
    "### Binding the Tool to the LLM\n",
    "With the get_metal_price tool defined, the next step is to bind it to the ChatOpenAI model. This enables the agent to invoke the tool during its execution based on the user's requests allowing it to interact with external data and perform actions beyond its native capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lsxVT0lUZQv4"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "tools = [get_metal_price]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuDuSrmQZQv4"
   },
   "source": [
    "## Task 4: Implementing the Agent Graph Structure\n",
    "\n",
    "In LangGraph, state plays a crucial role in tracking and updating information as the graph executes. As different parts of the graph run, the state evolves to reflect the changes and contains information that is passed between nodes.\n",
    "\n",
    "For example, in a conversational system like this one, the state is used to track the exchanged messages. Each time a new message is generated, it is added to the state and the updated state is passed through the nodes, ensuring the conversation progresses logically.\n",
    "\n",
    "### Defining the State\n",
    "To implement this in LangGraph, we define a state class that maintains a list of messages. Whenever a new message is produced it gets appended to this list, ensuring that the conversation history is continuously updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JHHXxYT1ZQv4"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KGbjrAOZQv4"
   },
   "source": [
    "### Defining the should_continue Function\n",
    "The `should_continue` function determines whether the conversation should proceed with further tool interactions or end. Specifically, it checks if the last message contains any tool calls (e.g., a request for metal prices).\n",
    "\n",
    "- If the last message includes tool calls, indicating that the agent has invoked an external tool, the conversation continues and moves to the \"tools\" node.\n",
    "- If there are no tool calls, the conversation ends, represented by the END state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KjppKPRDZQv4"
   },
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: GraphState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbyJRNRvZQv4"
   },
   "source": [
    "### Calling the Model\n",
    "The `call_model` function interacts with the Language Model (LLM) to generate a response based on the current state of the conversation. It takes the updated state as input, processes it and returns a model-generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZYflc7eZZQv4"
   },
   "outputs": [],
   "source": [
    "# Define the function that calls the model\n",
    "def call_model(state: GraphState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzxIHVa2ZQv4"
   },
   "source": [
    "### Creating the Assistant Node\n",
    "The `assistant` node is a key component responsible for processing the current state of the conversation and using the Language Model (LLM) to generate a relevant response. It evaluates the state, determines the appropriate course of action, and invokes the LLM to produce a response that aligns with the ongoing dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_fPD6W2SZQv4"
   },
   "outputs": [],
   "source": [
    "# Node\n",
    "def assistant(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc3No3agZQv5"
   },
   "source": [
    "### Creating the Tool Node\n",
    "The `tool_node` is responsible for managing interactions with external tools, such as fetching metal prices or performing other actions beyond the LLM's native capabilities. The tools themselves are defined earlier in the code, and the tool_node invokes these tools based on the current state and the needs of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vz2qlceBZQv5"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Node\n",
    "tools = [get_metal_price]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2FWZfGFZQv5"
   },
   "source": [
    "### Building the Graph\n",
    "The graph structure is the backbone of the agentic workflow, consisting of interconnected nodes and edges. To construct this graph, we use the StateGraph builder which allows us to define and connect various nodes. Each node represents a step in the process (e.g., the assistant node, tool node) and the edges dictate the flow of execution between these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "FeGI8G3KZQv5",
    "outputId": "31692c4e-f5c8-477c-cdba-84a1cfd1ad81"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Define a new graph for the agent\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "builder.add_edge(START, \"assistant\")\n",
    "\n",
    "# Making a conditional edge\n",
    "# should_continue will determine which node is called next.\n",
    "builder.add_conditional_edges(\"assistant\", should_continue, [\"tools\", END])\n",
    "\n",
    "# Making a normal edge from `tools` to `agent`.\n",
    "# The `agent` node will be called after the `tool`.\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile and display the graph for a visual overview\n",
    "react_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x76d5bc424ec0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlNB4fI4ZQv5"
   },
   "source": [
    "To test our setup, we will run the agent with a query. The agent will fetch the price of copper using the metals.dev API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzt0I-n2ZQv5",
    "outputId": "b4a32beb-1717-462e-9b42-cc698dc5216c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"What is the price of copper?\")]\n",
    "result = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esoHsop8ZQv5",
    "outputId": "2889a5e0-7f82-4d19-8319-112ed655c484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the price of copper?', additional_kwargs={}, response_metadata={}, id='45cdd62f-fa48-4d42-8b73-5055fb8d4f72'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_n0GnaDrEgkzGCZElYPQkK6Zr', 'function': {'arguments': '{\"metal_name\":\"copper\"}', 'name': 'get_metal_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 116, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DAGWARsRY61YKQuvaDNt5qm79Lijo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--019c6c0a-60c0-72b0-bb72-6f6e6f84e817-0', tool_calls=[{'name': 'get_metal_price', 'args': {'metal_name': 'copper'}, 'id': 'call_n0GnaDrEgkzGCZElYPQkK6Zr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 116, 'output_tokens': 18, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='0.3925', name='get_metal_price', id='2d774c46-2d8c-4d5d-b788-88857b51ac70', tool_call_id='call_n0GnaDrEgkzGCZElYPQkK6Zr'),\n",
       " AIMessage(content='The current price of copper is $0.3925 per gram.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 148, 'total_tokens': 163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DAGWCbfZbko6nd0eNqmroNz8eafsT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--019c6c0a-68d2-79c0-b447-d2886a63a2b6-0', usage_metadata={'input_tokens': 148, 'output_tokens': 15, 'total_tokens': 163, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsK_VEDSZQv6"
   },
   "source": [
    "## Task 5: Converting Agent Messages to Ragas Evaluation Format\n",
    "\n",
    "In the current implementation, the GraphState stores messages exchanged between the human user, the AI (LLM's responses), and any external tools (APIs or services the AI uses) in a list. Each message is an object in LangChain's format\n",
    "\n",
    "```python\n",
    "# Implementation of Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "```\n",
    "\n",
    "Each time a message is exchanged during agent execution, it gets added to the messages list in the GraphState. However, Ragas requires a specific message format for evaluating interactions.\n",
    "\n",
    "Ragas uses its own format to evaluate agent interactions. So, if you're using LangGraph, you will need to convert the LangChain message objects into Ragas message objects. This allows you to evaluate your AI agents with Ragas‚Äô built-in evaluation tools.\n",
    "\n",
    "**Goal:**  Convert the list of LangChain messages (e.g., HumanMessage, AIMessage, and ToolMessage) into the format expected by Ragas, so the evaluation framework can understand and process them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edpIDCgi6hkx"
   },
   "source": [
    "To convert a list of LangChain messages into a format suitable for Ragas evaluation, Ragas provides the function [convert_to_ragas_messages][ragas.integrations.langgraph.convert_to_ragas_messages], which can be used to transform LangChain messages into the format expected by Ragas.\n",
    "\n",
    "Here's how you can use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oGX9bx286hkx"
   },
   "outputs": [],
   "source": [
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "\n",
    "# Assuming 'result[\"messages\"]' contains the list of LangChain messages\n",
    "ragas_trace = convert_to_ragas_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Udcg7kCH6hkx",
    "outputId": "ac21080d-76de-4043-8604-40930aacac20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the price of copper?', metadata=None, type='human'),\n",
       " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='get_metal_price', args={'metal_name': 'copper'})]),\n",
       " ToolMessage(content='0.3925', metadata=None, type='tool'),\n",
       " AIMessage(content='The current price of copper is $0.3925 per gram.', metadata=None, type='ai', tool_calls=[])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_trace  # List of Ragas messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #1:\n",
    "\n",
    "Describe in your own words what a \"trace\" is.\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "I would say that trace is a step-by-step record of what the agent did to get an answer. It helps us see how it thought and what actions it took."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5mbTp5aZQv6"
   },
   "source": [
    "## Task 6: Evaluating the Agent's Performance  using Ragas Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H885v5sxZQv6"
   },
   "source": [
    "For this tutorial, let us evaluate the Agent with the following metrics:\n",
    "\n",
    "- [Tool call Accuracy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/#tool-call-accuracy):ToolCallAccuracy is a metric that can be used to evaluate the performance of the LLM in identifying and calling the required tools to complete a given task.  \n",
    "\n",
    "- [Agent Goal accuracy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/#agent-goal-accuracy): Agent goal accuracy is a metric that can be used to evaluate the performance of the LLM in identifying and achieving the goals of the user. This is a binary metric, with 1 indicating that the AI has achieved the goal and 0 indicating that the AI has not achieved the goal.\n",
    "- [Topic Adherence](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/): Topic adherence is a metric that can be used to ensure the Agent system is staying \"on-topic\", meaning that it's not straying from the intended use case. You can think of this as a kinda of faithfulness, where the responses of the LLM should stay faithful to the topic provided.\n",
    "\n",
    "\n",
    "First, let us actually run our Agent with a couple of queries, and make sure we have the ground truth labels for these queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #2:\n",
    "\n",
    "Describe *how* each of the above metrics are calculated. This will require you to read the documentation for each metric.\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "Tool Call Accuracy\n",
    "\n",
    "Tool Call Accuracy checks whether the agent selected and called the correct tool for the task. It compares the agent‚Äôs tool calls to the expected (ground truth) tool calls and measures how many were correct.\n",
    "\n",
    "Agent Goal Accuracy\n",
    "\n",
    "Agent Goal Accuracy is a binary score (0 or 1). It checks whether the agent successfully achieved the user‚Äôs goal ‚Äî if it did, the score is 1; if not, the score is 0.\n",
    "\n",
    "Topic Adherence\n",
    "\n",
    "Topic Adherence measures whether the agent stayed focused on the intended topic. It evaluates if the response is relevant to the given use case and does not drift into unrelated content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kRRIyTAZQv6"
   },
   "source": [
    "### Tool Call Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CC973Yq1ZQv6",
    "outputId": "8d18667e-a32c-4649-a9c9-49c734177b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import ToolCallAccuracy\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "import ragas.messages as r\n",
    "\n",
    "\n",
    "ragas_trace = convert_to_ragas_messages(\n",
    "    messages=result[\"messages\"]\n",
    ")  # List of Ragas messages converted using the Ragas function\n",
    "\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference_tool_calls=[\n",
    "        r.ToolCall(name=\"get_metal_price\", args={\"metal_name\": \"copper\"})\n",
    "    ],\n",
    ")\n",
    "\n",
    "tool_accuracy_scorer = ToolCallAccuracy()\n",
    "tool_accuracy_scorer.llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "await tool_accuracy_scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S14jlVw06hkx"
   },
   "source": [
    "Tool Call Accuracy: 1, because the LLM correctly identified and used the necessary tool (get_metal_price) with the correct parameters (i.e., metal name as \"copper\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGOL1CBsZQv6"
   },
   "source": [
    "### Agent Goal Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FA0kMvTfZQwB",
    "outputId": "1e2e4979-ef59-4af4-b395-b4bc846a16ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the price of 10 grams of silver?\")]\n",
    "\n",
    "result = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJr4Hxn8ZQwB",
    "outputId": "0282a461-d379-40c4-b186-fe4242bad882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the price of 10 grams of silver?', additional_kwargs={}, response_metadata={}, id='0f301940-0f51-42b3-9ab4-7e103ad1ef74'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sS0bxiSgTQTfynY8aISHz2PI', 'function': {'arguments': '{\"metal_name\":\"silver\"}', 'name': 'get_metal_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 120, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d611bd53c6', 'id': 'chatcmpl-DAGbCpg3YZH1zrnNu1dcgWmjtoUgk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--019c6c0f-2584-7171-80c3-dc3a0ce62758-0', tool_calls=[{'name': 'get_metal_price', 'args': {'metal_name': 'silver'}, 'id': 'call_sS0bxiSgTQTfynY8aISHz2PI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 120, 'output_tokens': 17, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='73.1825', name='get_metal_price', id='b926dfb0-cbb0-4c74-9c05-1b700aa6d5d4', tool_call_id='call_sS0bxiSgTQTfynY8aISHz2PI'),\n",
       " AIMessage(content='The current price of silver is approximately $73.18 per gram. Therefore, the price for 10 grams of silver would be around $731.82.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 151, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DAGbDVzRnTwqlpBAM8n5muOsbv7wc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--019c6c0f-2c66-7213-819d-5875f9722308-0', usage_metadata={'input_tokens': 151, 'output_tokens': 33, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"]  # List of Langchain messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StDNqR2vZQwB",
    "outputId": "a92e93c6-ece8-4f72-a92d-d1e512175899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the price of 10 grams of silver?', metadata=None, type='human'),\n",
       " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='get_metal_price', args={'metal_name': 'silver'})]),\n",
       " ToolMessage(content='73.1825', metadata=None, type='tool'),\n",
       " AIMessage(content='The current price of silver is approximately $73.18 per gram. Therefore, the price for 10 grams of silver would be around $731.82.', metadata=None, type='ai', tool_calls=[])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "\n",
    "ragas_trace = convert_to_ragas_messages(\n",
    "    result[\"messages\"]\n",
    ")  # List of Ragas messages converted using the Ragas function\n",
    "ragas_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6u9-RYdZQwB",
    "outputId": "76ffcaa7-676b-46f9-e931-dddfabee16c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.metrics import AgentGoalAccuracyWithReference\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference=\"Price of 10 grams of silver\",\n",
    ")\n",
    "\n",
    "scorer = AgentGoalAccuracyWithReference()\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "scorer.llm = evaluator_llm\n",
    "await scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K71VkA7o6hk0"
   },
   "source": [
    "Agent Goal Accuracy: 1, because the LLM correctly achieved the user‚Äôs goal of retrieving the price of 10 grams of silver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0fKvUqpDQVK"
   },
   "source": [
    "### Topic Adherence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4ouIaXBNDZgc"
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"How fast can an eagle fly?\")]\n",
    "\n",
    "result = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBRGGNb4DyBa",
    "outputId": "b1de5ece-c17d-4ea1-bdfb-ba90da3ae343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How fast can an eagle fly?', additional_kwargs={}, response_metadata={}, id='11545262-f271-446b-b8ad-c391c66aa63d'),\n",
       " AIMessage(content='Eagles are known for their impressive flying abilities. The speed of an eagle can vary depending on the species and whether they are gliding or diving. \\n\\n- **Gliding:** Most eagles can glide at speeds of around 20 to 40 miles per hour (32 to 64 kilometers per hour).\\n- **Diving:** When hunting, some species, like the peregrine falcon (not an eagle but often compared), can dive at speeds exceeding 150 miles per hour (241 kilometers per hour). Eagles may not dive quite as fast but can reach speeds of about 75 to 100 miles per hour (120 to 160 kilometers per hour) during a stoop (a high-speed dive).\\n\\nThe golden eagle and the bald eagle are among the fastest, showcasing remarkable agility and power during flight.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 116, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DAGc65HCWOmR7qRcbV1pqG1sn0qAu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--019c6c0f-fef8-75c2-b83c-10c9e41edd8f-0', usage_metadata={'input_tokens': 116, 'output_tokens': 164, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3i7NIgjD8ec",
    "outputId": "4aaa7855-2108-48d4-a872-9428b0981572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How fast can an eagle fly?', metadata=None, type='human'),\n",
       " AIMessage(content='Eagles are known for their impressive flying abilities. The speed of an eagle can vary depending on the species and whether they are gliding or diving. \\n\\n- **Gliding:** Most eagles can glide at speeds of around 20 to 40 miles per hour (32 to 64 kilometers per hour).\\n- **Diving:** When hunting, some species, like the peregrine falcon (not an eagle but often compared), can dive at speeds exceeding 150 miles per hour (241 kilometers per hour). Eagles may not dive quite as fast but can reach speeds of about 75 to 100 miles per hour (120 to 160 kilometers per hour) during a stoop (a high-speed dive).\\n\\nThe golden eagle and the bald eagle are among the fastest, showcasing remarkable agility and power during flight.', metadata=None, type='ai', tool_calls=[])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "\n",
    "ragas_trace = convert_to_ragas_messages(\n",
    "    result[\"messages\"]\n",
    ")  # List of Ragas messages converted using the Ragas function\n",
    "ragas_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLTMVPaMDzal",
    "outputId": "44fb96b3-0628-4c65-e87c-4e0a5a795047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import TopicAdherenceScore\n",
    "\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference_topics = [\"metals\"]\n",
    ")\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "scorer = TopicAdherenceScore(llm = evaluator_llm, mode=\"precision\")\n",
    "await scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac2I2MZJEcK5"
   },
   "source": [
    "As we can see, the current implementation fails due to talking about birds, when it should be talking about metal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #3:\n",
    "\n",
    "If you were deploying this metal price agent as a production wellness assistant (imagine it's a financial wellness tool for tracking investment metals), what are the implications of each metric (Tool Call Accuracy, Agent Goal Accuracy, Topic Adherence) for user trust and safety?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "Tool Call Accuracy\n",
    "\n",
    "If the agent calls the wrong tool, it could return incorrect metal prices or outdated data. This would quickly reduce user trust because people rely on accurate financial information.\n",
    "\n",
    "Agent Goal Accuracy\n",
    "\n",
    "If the agent fails to achieve the user‚Äôs goal (like getting the correct gold price), users may feel the tool is unreliable. In financial wellness, failing to meet goals could lead to poor decisions and loss of confidence.\n",
    "\n",
    "Topic Adherence\n",
    "\n",
    "If the agent goes off-topic or gives unrelated advice, users may feel confused or unsafe. Staying focused on financial metal tracking helps maintain clarity, professionalism, and trust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #4:\n",
    "\n",
    "How would you design a comprehensive test suite for evaluating this metal price agent? What test cases would you include to ensure robustness across the three metrics (Tool Call Accuracy, Agent Goal Accuracy, Topic Adherence)?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "Tool Call Accuracy\n",
    "\n",
    "I would test simple, complex, and edge-case metal price queries to make sure the agent calls the correct pricing tool every time. I would also include invalid or unclear questions to see if it avoids calling the wrong tool.\n",
    "\n",
    "Agent Goal Accuracy\n",
    "\n",
    "I would include clear goal-based tasks like price lookups, comparisons, and multi-step questions. Each test would have a defined expected result so we can check if the agent truly completed the user‚Äôs request.\n",
    "\n",
    "Topic Adherence\n",
    "\n",
    "I would test off-topic and mixed-topic prompts to ensure the agent stays focused on metal investments. The agent should either answer within scope or politely redirect unrelated questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #1: Evaluate Tool Call Accuracy with a New Query\n",
    "\n",
    "Create a new test case for Tool Call Accuracy. Run the agent with a different metal query (e.g., \"What is the price of platinum?\") and evaluate its tool call accuracy.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a new query for the agent\n",
    "2. Run the agent and collect the trace\n",
    "3. Define the expected reference tool calls\n",
    "4. Evaluate using ToolCallAccuracy\n",
    "5. Document your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Tool Call Accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from ragas.metrics import ToolCallAccuracy\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "import ragas.messages as r\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) Create a new query\n",
    "messages = [HumanMessage(content=\"What is the price of platinum?\")]\n",
    "\n",
    "# 2) Run the agent and collect the trace (LangGraph messages)\n",
    "result = react_graph.invoke({\"messages\": messages})\n",
    "\n",
    "# 3) Convert to Ragas format\n",
    "ragas_trace = convert_to_ragas_messages(messages=result[\"messages\"])\n",
    "\n",
    "# 4) Define expected reference tool calls\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference_tool_calls=[\n",
    "        r.ToolCall(name=\"get_metal_price\", args={\"metal_name\": \"platinum\"})\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 5) Evaluate using ToolCallAccuracy\n",
    "tool_accuracy_scorer = ToolCallAccuracy()\n",
    "tool_accuracy_scorer.llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "score = await tool_accuracy_scorer.multi_turn_ascore(sample)\n",
    "print(\"Tool Call Accuracy score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query: ‚ÄúWhat is the price of platinum?‚Äù\n",
    "\n",
    "Expected tool call: get_metal_price(metal_name=\"platinum\")\n",
    "\n",
    "Result: Tool Call Accuracy = <paste score> (1 means it matched the expected tool call, 0 means it didn‚Äôt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2: Evaluate Topic Adherence with an On-Topic Query\n",
    "\n",
    "Create a test case that should PASS the Topic Adherence check. Run the agent with a metals-related query and verify it stays on topic.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a metals-related query for the agent\n",
    "2. Run the agent and collect the trace\n",
    "3. Create a MultiTurnSample with reference_topics=[\"metals\"]\n",
    "4. Evaluate using TopicAdherenceScore\n",
    "5. The score should be 1.0 (or close to it) since the query is on-topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACE KEYS:\n",
      "['messages']\n",
      "\n",
      "First few items in result['messages'] (type and value):\n",
      "0 <class 'langchain_core.messages.human.HumanMessage'>\n",
      "HumanMessage(content='How has the price of silver changed over the past month?', additional_kwargs={}, response_metadata={}, id='99a03725-9c97-4758-ae74-76cc2511a9cf')\n",
      "---\n",
      "1 <class 'langchain_core.messages.ai.AIMessage'>\n",
      "AIMessage(content=\"I currently don't have access to historical price data for silver. However, I can fetch the current price of silver. Would you like me to do that?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 121, 'total_tokens': 153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d611bd53c6', 'id': 'chatcmpl-DAGpFfhTBVYymq04FPIRgzCdeJqp6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--019c6c1c-6f8b-7b22-996e-6bccb7a2e244-0', usage_metadata={'input_tokens': 121, 'output_tokens': 32, 'total_tokens': 153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m topic_scorer.multi_turn_ascore(sample)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     score = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# if there's no running loop, create one\u001b[39;00m\n\u001b[32m     82\u001b[39m     score = asyncio.run(run_score())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mrun_score\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_score\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m topic_scorer.multi_turn_ascore(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/ragas/metrics/base.py:630\u001b[39m, in \u001b[36mMultiTurnMetric.multi_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    628\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n\u001b[32m    629\u001b[39m         rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/ragas/metrics/base.py:623\u001b[39m, in \u001b[36mMultiTurnMetric.multi_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    616\u001b[39m rm, group_cm = new_group(\n\u001b[32m    617\u001b[39m     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    618\u001b[39m     inputs=sample.to_dict(),\n\u001b[32m    619\u001b[39m     callbacks=callbacks,\n\u001b[32m    620\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.METRIC},\n\u001b[32m    621\u001b[39m )\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     score = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    624\u001b[39m         \u001b[38;5;28mself\u001b[39m._multi_turn_ascore(sample=sample, callbacks=group_cm),\n\u001b[32m    625\u001b[39m         timeout=timeout,\n\u001b[32m    626\u001b[39m     )\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    628\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:507\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/ragas/metrics/_topic_adherence.py:167\u001b[39m, in \u001b[36mTopicAdherenceScore._multi_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    164\u001b[39m user_input = sample.pretty_repr()\n\u001b[32m    166\u001b[39m prompt_input = TopicExtractionInput(user_input=user_input)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.topic_extraction_prompt.generate(\n\u001b[32m    168\u001b[39m     data=prompt_input, llm=\u001b[38;5;28mself\u001b[39m.llm, callbacks=callbacks\n\u001b[32m    169\u001b[39m )\n\u001b[32m    170\u001b[39m topics = response.topics\n\u001b[32m    172\u001b[39m topic_answered_verdict = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:126\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    123\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    127\u001b[39m     llm=llm,\n\u001b[32m    128\u001b[39m     data=data,\n\u001b[32m    129\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    130\u001b[39m     temperature=temperature,\n\u001b[32m    131\u001b[39m     stop=stop,\n\u001b[32m    132\u001b[39m     callbacks=callbacks,\n\u001b[32m    133\u001b[39m     retries_left=retries_left,\n\u001b[32m    134\u001b[39m )\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:187\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    180\u001b[39m prompt_rm, prompt_cb = new_group(\n\u001b[32m    181\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    182\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: processed_data},\n\u001b[32m    183\u001b[39m     callbacks=callbacks,\n\u001b[32m    184\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.RAGAS_PROMPT},\n\u001b[32m    185\u001b[39m )\n\u001b[32m    186\u001b[39m prompt_value = PromptValue(text=\u001b[38;5;28mself\u001b[39m.to_string(processed_data))\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m output_models = []\n\u001b[32m    196\u001b[39m parser = RagasOutputParser(pydantic_object=\u001b[38;5;28mself\u001b[39m.output_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:824\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    809\u001b[39m inheritable_metadata = {\n\u001b[32m    810\u001b[39m     **(metadata \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    811\u001b[39m     **\u001b[38;5;28mself\u001b[39m._get_ls_params(stop=stop, **kwargs),\n\u001b[32m    812\u001b[39m }\n\u001b[32m    814\u001b[39m callback_manager = CallbackManager.configure(\n\u001b[32m    815\u001b[39m     callbacks,\n\u001b[32m    816\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m   (...)\u001b[39m\u001b[32m    821\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata,\n\u001b[32m    822\u001b[39m )\n\u001b[32m    823\u001b[39m messages_to_trace = [\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[43m_format_for_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m    825\u001b[39m ]\n\u001b[32m    826\u001b[39m run_managers = callback_manager.on_chat_model_start(\n\u001b[32m    827\u001b[39m     \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m    828\u001b[39m     messages_to_trace,\n\u001b[32m   (...)\u001b[39m\u001b[32m    833\u001b[39m     batch_size=\u001b[38;5;28mlen\u001b[39m(messages),\n\u001b[32m    834\u001b[39m )\n\u001b[32m    835\u001b[39m results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIE9/10_Evaluating_RAG_With_Ragas/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:125\u001b[39m, in \u001b[36m_format_for_tracing\u001b[39m\u001b[34m(messages)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[32m    124\u001b[39m     message_to_trace = message\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    126\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(message.content):\n\u001b[32m    127\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(block, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    128\u001b[39m                 \u001b[38;5;66;03m# Update image content blocks to OpenAI # Chat Completions format.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Robust runner for TopicAdherenceScore (handles strings/dicts/langchain msgs)\n",
    "from pprint import pprint\n",
    "import asyncio\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from ragas.metrics import TopicAdherenceScore\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1) Run the agent (or reuse your previous `result`)\n",
    "messages = [HumanMessage(content=\"How has the price of silver changed over the past month?\")]\n",
    "result = react_graph.invoke({\"messages\": messages})\n",
    "\n",
    "# 2) Inspect what the agent returned so you can see message types\n",
    "print(\"TRACE KEYS:\")\n",
    "pprint(list(result.keys()))\n",
    "print(\"\\nFirst few items in result['messages'] (type and value):\")\n",
    "for idx, m in enumerate(result.get(\"messages\", [])[:10]):\n",
    "    print(idx, type(m))\n",
    "    pprint(m)\n",
    "    print(\"---\")\n",
    "\n",
    "# 3) Normalize messages -> ensure langchain-style message objects\n",
    "raw_msgs = result.get(\"messages\", [])\n",
    "normalized = []\n",
    "for m in raw_msgs:\n",
    "    # already a langchain message object\n",
    "    if isinstance(m, (HumanMessage, AIMessage, SystemMessage)):\n",
    "        normalized.append(m)\n",
    "        continue\n",
    "\n",
    "    # if it's a dict with 'role' and 'content'\n",
    "    if isinstance(m, dict):\n",
    "        role = m.get(\"role\", \"user\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        # sometimes content itself may be a list or dict; stringify if needed\n",
    "        if isinstance(content, (list, dict)):\n",
    "            content = str(content)\n",
    "        if role.lower().startswith(\"sys\"):\n",
    "            normalized.append(SystemMessage(content=content))\n",
    "        elif role.lower().startswith(\"user\"):\n",
    "            normalized.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            normalized.append(AIMessage(content=content))\n",
    "        continue\n",
    "\n",
    "    # if it's a plain string -> treat as user/human content\n",
    "    if isinstance(m, str):\n",
    "        normalized.append(HumanMessage(content=m))\n",
    "        continue\n",
    "\n",
    "    # fallback: stringify anything else\n",
    "    normalized.append(HumanMessage(content=str(m)))\n",
    "\n",
    "# 4) Convert to ragas messages\n",
    "try:\n",
    "    ragas_trace = convert_to_ragas_messages(messages=normalized)\n",
    "except Exception as e:\n",
    "    print(\"Error converting to ragas messages:\", e)\n",
    "    # show a sample normalized message to debug\n",
    "    print(\"Example normalized message (first):\", normalized[0] if normalized else \"NONE\")\n",
    "    raise\n",
    "\n",
    "# 5) Build the MultiTurnSample with reference_topics\n",
    "sample = MultiTurnSample(user_input=ragas_trace, reference_topics=[\"metals\"])\n",
    "\n",
    "# 6) Create scorer and set an LLM (this is required)\n",
    "topic_scorer = TopicAdherenceScore()\n",
    "topic_scorer.llm = ChatOpenAI(model=\"gpt-4o-mini\")  # change to an available model if needed\n",
    "\n",
    "# 7) Run the scorer (async-safe)\n",
    "async def run_score():\n",
    "    return await topic_scorer.multi_turn_ascore(sample)\n",
    "\n",
    "try:\n",
    "    score = asyncio.get_event_loop().run_until_complete(run_score())\n",
    "except RuntimeError:\n",
    "    # if there's no running loop, create one\n",
    "    score = asyncio.run(run_score())\n",
    "\n",
    "print(\"\\nTopic Adherence score:\", score)\n",
    "print(\"Interpretation:\", \"PASS ‚Äî stayed on-topic.\" if score >= 0.95 else \"FAIL or partial ‚Äî may have drifted.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
